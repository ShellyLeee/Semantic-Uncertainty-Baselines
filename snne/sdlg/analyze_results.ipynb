{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "from utils import compute_semantic_clusters, compute_semantic_entropy, prepare_results\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**输入结构**（每个样本一份 results_dict，每个 run 两条通道）：\n",
    "\n",
    "- run_key ∈ {\"sdlg\",\"baseline\"}\n",
    "- results_dict[run_key]['generations']：生成的回答序列（第 0 个通常是 most-likely）\n",
    "- results_dict[run_key]['likelihoods']：对应的负对数似然 / token 概率等\n",
    "- results_dict[run_key][f'semantic_pairs_{model_type}']：\n",
    "  - semantic_pairs：NLI/DeBERTa 得到的语义等价矩阵（bool，上三角 → 对称化）\n",
    "  - （可选）cleaned_semantic_pairs：清洗过的等价矩阵\n",
    "\n",
    "**核心对比流程**（逐渐增加可用的 generations 数量 n，从 2 到 num_total_gens）\n",
    "\n",
    "1. 取前 n 个生成：\n",
    "- baseline：用 boolean_mask（前 n 个为 True）。\n",
    "- SDLG：除了 boolean_mask，还构造 mask（重要性权重）：\n",
    "\n",
    "```\n",
    "mask = tensor([1] + [gen['token_likelihood'] for gen in generations[1:]])\n",
    "# 注意：SDLG里这个mask是 (0,1) 区间的“权重”，随后会做 L1 归一化\n",
    "```\n",
    "\n",
    "2. 截取对应的 semantic_pairs 子矩阵（并与转置求交，保证对称）。\n",
    "\n",
    "3. 聚类（compute_semantic_clusters）：把 n 个回答按语义连通分量/团划成若干簇，得到 semantic_difference 结构（含簇 id）。\n",
    "\n",
    "4. 算语义熵 SE（compute_semantic_entropy）：\n",
    "- baseline：权重 = boolean_mask.float()（等权）\n",
    "- SDLG：权重 = normalize(mask[boolean_mask])（重要性采样权重）\n",
    "- 两个版本：\n",
    "  - \"normalised_semantic_entropy\"（按簇概率正规化）\n",
    "  - \"unnormalised_semantic_entropy\"（未正规化版本）\n",
    "- 还特意算了 baseline 的一个 错误估计（mc_estimate_over_clusters=True），在图里用 “(incorrect estimate)” 对比。\n",
    "\n",
    "5. 把 SE 当成“不确定度分数”，用一个正确性度量（如 bleurt/rouge/rougeL 等）阈值化成 “对/错” 二分类标签；然后计算 AUROC：\n",
    "- 标签：list_correct_labels = ~ (score >= threshold) → “1 = 错误”\n",
    "- 预测：SE（值越大，越“不确定”）\n",
    "- roc_auc_score(labels, SE) → 不同 n（#gen）下的曲线\n",
    "\n",
    "6. 记录 CSV + 画图：\n",
    "- 同一张图里画 \"sdlg\" 和 \"baseline\" 的 AUROC 随 n（使用的 generations 数） 的变化；\n",
    "- baseline 还额外画一个 “incorrect estimate” 曲线（mc_estimate_over_clusters）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ['coqa', 'trivia_qa', 'truthful_qa'][0]\n",
    "# correctness_metric = [\"rougeL\", \"bleurt\", \"rouge1\"][2]\n",
    "dataset = 'trivia_qa'\n",
    "correctness_metric = 'rougeL'\n",
    "\n",
    "if dataset == 'truthful_qa':\n",
    "    correctness_metric += \"-diff\"\n",
    "\n",
    "correctness_threshold_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "num_total_gens = 10\n",
    "\n",
    "run_ids = ['tqa_llama2-13b-chat-1']\n",
    "\n",
    "model_type = \"deberta-large-mnli\"\n",
    "auroc_keys = [\"normalised_semantic_entropy\", \"unnormalised_semantic_entropy\"] \n",
    "# auroc_keys += [\"cleaned_normalised_semantic_entropy\", \"cleaned_unnormalised_semantic_entropy\"]\n",
    "\n",
    "log_results = True\n",
    "plot_results = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the existence of the pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 替换为你自己的文件路径\n",
    "file_path = 'results/tqa_llama2-7b-chat-3/results_dict_0.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "print(\"字典键：\", data.keys())\n",
    "# for k, v in list(data.items())[:]:\n",
    "#     print(f\"{k}: {v}\")\n",
    "\n",
    "# 正确访问方式\n",
    "#print(data[\"input_ids\"])\n",
    "print(\"Question:\", data[\"question\"])\n",
    "print(\"Correctness:\", data[\"correctness_dict\"])\n",
    "print(\"sdlg generations:\", data[\"sdlg\"][\"generations\"])\n",
    "print(\"baseline generations:\", data[\"baseline\"][\"generations\"])\n",
    "\n",
    "if not data[\"sdlg\"][\"generations\"]:\n",
    "    print(\"⚠️ SDLG generations 是空的\")\n",
    "if not data[\"baseline\"][\"generations\"]:\n",
    "    print(\"⚠️ Baseline generations 是空的\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cleaned = \"cleaned_normalised_semantic_entropy\" in auroc_keys or \"cleaned_unnormalised_semantic_entropy\" in auroc_keys\n",
    "\n",
    "\n",
    "\n",
    "if plot_results:\n",
    "    fig_dict = {}\n",
    "    for correctness_threshold in correctness_threshold_list:\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=len(auroc_keys), figsize=(5*len(auroc_keys), 5))\n",
    "        fig_dict[correctness_threshold] = {\"fig\": fig, \"axs\": axs}\n",
    "\n",
    "color_count = 0\n",
    "for run_id in run_ids:\n",
    "\n",
    "    basepath = os.path.join('results', run_id)\n",
    "\n",
    "    for run_key in [\"sdlg\", \"baseline\"]:\n",
    "\n",
    "        if plot_results:\n",
    "            plot_dict, plot_dict_kuhn = {}, {}\n",
    "            for correctness_threshold in correctness_threshold_list:\n",
    "                plot_dict[correctness_threshold] = {'plot_data_x': [], 'plot_data_y': []}\n",
    "                plot_dict_kuhn[correctness_threshold] = {'plot_data_x': [], 'plot_data_y': []}\n",
    "\n",
    "        list_results_dict, list_rougeL, dataset_size = prepare_results(num_samples=8000,\n",
    "                                                                        run_key=run_key,\n",
    "                                                                        metric=correctness_metric,\n",
    "                                                                        start_sample_id=0,\n",
    "                                                                        base_path=basepath)\n",
    "\n",
    "        # iterate over num_gens\n",
    "        for num_gens in tqdm(range(2, num_total_gens+1)):\n",
    "\n",
    "            all_semantic_entropies, all_semantic_entropies_kuhn = [], []\n",
    "            list_num_semantic_clusters, list_num_generations = [], []\n",
    "            \n",
    "            # iterate over instances\n",
    "            for i, results_dict in enumerate(list_results_dict):\n",
    "\n",
    "                # ---------- create mask of considered generations\n",
    "                if num_gens < len(results_dict[run_key]['generations']):\n",
    "                    boolean_mask = [True] * num_gens + [False] * (len(results_dict[run_key]['generations']) - num_gens)\n",
    "                else:\n",
    "                    boolean_mask = [True] * len(results_dict[run_key]['generations'])\n",
    "\n",
    "                boolean_mask = torch.tensor(boolean_mask)\n",
    "\n",
    "                if run_key == \"sdlg\":\n",
    "                    mask = torch.tensor([1] + [gen['token_likelihood'] for gen in results_dict[run_key]['generations'][1:]])\n",
    "                    assert torch.all(mask > 0) and torch.all(mask[1:] < 1), f\"mask: {mask}\"\n",
    "                elif run_key == \"baseline\":\n",
    "                    mask = boolean_mask\n",
    "                # ----------\n",
    "\n",
    "                list_num_generations.append(torch.sum(boolean_mask).item())\n",
    "\n",
    "                all_considered_generations, all_considered_likelihoods = [], []\n",
    "                for m, included in enumerate(boolean_mask):\n",
    "                    if included:\n",
    "                        all_considered_generations.append(results_dict[run_key]['generations'][m])\n",
    "                        all_considered_likelihoods.append(results_dict[run_key]['likelihoods'][m])\n",
    "\n",
    "                if results_dict[run_key][f'semantic_pairs_{model_type}']['semantic_pairs'].shape[0] > 1:\n",
    "                    semantic_pairs = results_dict[run_key][f'semantic_pairs_{model_type}']['semantic_pairs'][boolean_mask, :][:, boolean_mask]\n",
    "                    if compute_cleaned:\n",
    "                        cleaned_semantic_pairs = results_dict[run_key][f'semantic_pairs_{model_type}']['cleaned_semantic_pairs'][boolean_mask, :][:, boolean_mask]\n",
    "                else:\n",
    "                    # deal with single generations\n",
    "                    assert boolean_mask.item() == True, f\"mask: {boolean_mask}\"\n",
    "                    semantic_pairs = results_dict[run_key][f'semantic_pairs_{model_type}']['semantic_pairs']\n",
    "                    if compute_cleaned:\n",
    "                        cleaned_semantic_pairs = results_dict[run_key][f'semantic_pairs_{model_type}']['cleaned_semantic_pairs']\n",
    "\n",
    "                # compute symmetric adjacency matrix\n",
    "                semantic_pairs = semantic_pairs & semantic_pairs.T\n",
    "                assert np.array_equal(semantic_pairs, semantic_pairs.T)\n",
    "                if compute_cleaned:\n",
    "                    cleaned_semantic_pairs = cleaned_semantic_pairs & cleaned_semantic_pairs.T\n",
    "                    assert np.array_equal(cleaned_semantic_pairs, cleaned_semantic_pairs.T)\n",
    "\n",
    "                # compute semantic clusters\n",
    "                semantic_difference = compute_semantic_clusters(generations=all_considered_generations, \n",
    "                                                                        cleaned_semantic_pairs=cleaned_semantic_pairs if compute_cleaned else None,\n",
    "                                                                        semantic_pairs=semantic_pairs,\n",
    "                                                                        compute_cleaned=compute_cleaned)\n",
    "                list_num_semantic_clusters.append(torch.unique(semantic_difference[\"semantic_clusters\"]).shape[0])\n",
    "\n",
    "                # compute semantic entropy\n",
    "                weights = boolean_mask[boolean_mask].to(torch.float32) if run_key == \"baseline\" else torch.nn.functional.normalize(mask[boolean_mask].to(torch.float32), p=1, dim=0)\n",
    "                all_semantic_entropies.append(\n",
    "                    compute_semantic_entropy(weights=weights,\n",
    "                                             mc_estimate_over_clusters=False,\n",
    "                                             neg_log_likelihoods=all_considered_likelihoods, \n",
    "                                             semantic_difference=semantic_difference,\n",
    "                                             compute_cleaned=compute_cleaned))\n",
    "\n",
    "                if run_key == \"baseline\":\n",
    "                    all_semantic_entropies_kuhn.append(\n",
    "                        compute_semantic_entropy(weights=weights,\n",
    "                                                 mc_estimate_over_clusters=True,\n",
    "                                                 neg_log_likelihoods=all_considered_likelihoods, \n",
    "                                                 semantic_difference=semantic_difference,\n",
    "                                                 compute_cleaned=compute_cleaned))\n",
    "\n",
    "            for r, correctness_threshold in enumerate(correctness_threshold_list):\n",
    "                list_correct_labels = torch.logical_not((torch.tensor(list_rougeL) >= correctness_threshold))\n",
    "                aurocs, aurocs_kuhn = {}, {}\n",
    "                for k, key in enumerate(auroc_keys):\n",
    "                    aurocs[key] = roc_auc_score(list_correct_labels,\n",
    "                                                [d[key] for d in all_semantic_entropies])\n",
    "\n",
    "                    if run_key == \"baseline\":\n",
    "                        aurocs_kuhn[key] = roc_auc_score(list_correct_labels,\n",
    "                                                        [d[key] for d in all_semantic_entropies_kuhn])\n",
    "\n",
    "                if plot_results:\n",
    "                    plot_dict[correctness_threshold]['plot_data_x'].append(num_gens) # sum(list_num_generations) / len(list_num_generations))\n",
    "                    plot_dict[correctness_threshold]['plot_data_y'].append(aurocs)\n",
    "\n",
    "                    if run_key == \"baseline\":\n",
    "                        plot_dict_kuhn[correctness_threshold]['plot_data_x'].append(num_gens)\n",
    "                        plot_dict_kuhn[correctness_threshold]['plot_data_y'].append(aurocs_kuhn)\n",
    "                    \n",
    "                if log_results:\n",
    "                    with open(os.path.join(basepath, f'auroc_results.csv'), 'a') as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        writer.writerow([run_id, \n",
    "                                         run_key, \n",
    "                                         num_gens, \n",
    "                                         correctness_threshold, \n",
    "                                         \"importance_sampling\", \n",
    "                                         aurocs[\"normalised_semantic_entropy\"], \n",
    "                                         aurocs[\"unnormalised_semantic_entropy\"]])\n",
    "                        if run_key == \"baseline\":\n",
    "                            writer.writerow([run_id, \n",
    "                                             run_key, \n",
    "                                             num_gens, \n",
    "                                             correctness_threshold, \n",
    "                                             \"mc_estimate_over_clusters\", \n",
    "                                             aurocs_kuhn[\"normalised_semantic_entropy\"], \n",
    "                                             aurocs_kuhn[\"unnormalised_semantic_entropy\"]])\n",
    "\n",
    "                    with open(os.path.join(basepath, f'avg_num_clusters_found.csv'), 'a') as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        clusters_correct_answer = torch.tensor(list_num_semantic_clusters)[list_correct_labels == 0]\n",
    "                        clusters_wrong_answer = torch.tensor(list_num_semantic_clusters)[list_correct_labels == 1]\n",
    "                        writer.writerow([run_id, run_key, num_gens, correctness_threshold, \n",
    "                                        sum(list_num_semantic_clusters) / len(list_num_semantic_clusters), \n",
    "                                        torch.mean(clusters_correct_answer.float()).item(), sum(list_correct_labels).item(),\n",
    "                                        torch.mean(clusters_wrong_answer.float()).item(), (len(list_correct_labels) - sum(list_correct_labels)).item()])\n",
    "\n",
    "        if plot_results:\n",
    "            for correctness_threshold in correctness_threshold_list:\n",
    "                for k, key in enumerate(auroc_keys):\n",
    "                    x_values = plot_dict[correctness_threshold]['plot_data_x']\n",
    "                    y_values = [d[key] for d in plot_dict[correctness_threshold]['plot_data_y']]\n",
    "                    fig_dict[correctness_threshold][\"axs\"][k].plot(x_values, \n",
    "                                                                   y_values, \n",
    "                                                                   c=f\"C{color_count}\", \n",
    "                                                                   alpha=0.8, \n",
    "                                                                   marker=\"o\" if run_key==\"sdlg\" else \"^\", \n",
    "                                                                   label=f\"{run_id} ({run_key})\")\n",
    "                    \n",
    "                    if run_key == \"baseline\":\n",
    "                        x_values = plot_dict_kuhn[correctness_threshold]['plot_data_x']\n",
    "                        y_values = [d[key] for d in plot_dict_kuhn[correctness_threshold]['plot_data_y']]\n",
    "                        fig_dict[correctness_threshold][\"axs\"][k].plot(x_values, \n",
    "                                                                       y_values, \n",
    "                                                                       c=f\"C{color_count}\", \n",
    "                                                                       alpha=0.4, \n",
    "                                                                       marker=\"v\", \n",
    "                                                                       label=f\"{run_id} (incorrect estimate)\")\n",
    "\n",
    "                    fig_dict[correctness_threshold][\"axs\"][k].set_xlabel('# generations')\n",
    "                    fig_dict[correctness_threshold][\"axs\"][k].set_ylabel(f'AUROC')\n",
    "                    fig_dict[correctness_threshold][\"axs\"][k].set_xlim([1, num_total_gens+1])\n",
    "                    fig_dict[correctness_threshold][\"axs\"][k].set_xticks(range(2, num_total_gens+1, 2))\n",
    "                    fig_dict[correctness_threshold][\"axs\"][k].set_ylim([0.5, 1])\n",
    "                    fig_dict[correctness_threshold][\"axs\"][k].legend()\n",
    "                    fig_dict[correctness_threshold][\"axs\"][k].set_title(key)\n",
    "                    \n",
    "                    if run_key == \"baseline\":\n",
    "                        fig_dict[correctness_threshold][\"fig\"].suptitle(f'Correctness threshold: {correctness_threshold}', fontsize=12)\n",
    "                        fig_dict[correctness_threshold][\"fig\"].tight_layout()\n",
    "                        fig_dict[correctness_threshold][\"fig\"].savefig(os.path.join(basepath, f'{model_type}_{dataset_size}samples_{correctness_threshold}threshold.png'))\n",
    "\n",
    "        color_count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qualm_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
